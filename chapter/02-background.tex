In this section, the required theoretical background and context for this thesis are explained. First, fundamental concepts of software development, the agile software development lifecycle (SDLC), Continuous Integration (CI), and software project hosting platforms are introduced. The second part explores Generative AI and LLMs with their rising role in software development practices. The third part examines the evolution and current state of Automated Program Repair (APR) with examples of existing approaches.

\section{Software Development}

The following section introduces core concepts of software development, starting with the software development lifecycle, followed by the importance of Continuous Integration (CI) in modern software development, and the role of software project hosting platforms.

\subsection{Software Development Lifecycle}
%TODO add tickets that are created by developers, product managers, ...
Engineering and developing software is a complex process, consisting of multiple different tasks. To structure this process, software development lifecycle models have been introduced. These frameworks constantly evolve to adapt to the changing needs of software creation. One of the most promising and widely used models today is Agile \cite{rupareliaSoftwareDevelopmentLifecycle2010, abrahamssonAgileSoftwareDevelopment2017}.

The Agile lifecycle introduces an iterative approach to software development, focusing on collaboration, feedback, and adaptability. The goal is frequent delivery of small functional software features, allowing continuous improvement and adaptation to changing requirements \cite{rupareliaSoftwareDevelopmentLifecycle2010, abrahamssonAgileSoftwareDevelopment2017}. Agile frameworks like Scrum or Kanban are used to apply this approach in a development environment \cite{zayatFrameworkStudyAgile2020}.

An Agile iteration consists of multiple stages. Figure \ref{fig\:agile-cycle} shows an example of an agile iteration interpretation. Iterations start with a planning phase where requirements are gathered and prioritized. Secondly, the architecture and design of the required changes are constructed in the design phase. The third stage involves developing the prioritized requirements. After development, the changes are tested for issues or bugs in the testing stage. Upon successful integration and testing, the changes are released in the deployment stage. Finally, internal and user feedback is collected for review \cite{huoSoftwareQualityAgile2004}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/agile-cycle.png}
    \caption{Agile software development lifecycle}
    \label{fig:agile-cycle}
\end{figure}

When bugs arise during an iteration, requirements can be reprioritized, and the iteration can be adapted to fix these issues. This adaptability is a key feature of Agile software development, allowing teams to quickly respond to changing requirements and issues that can slow down the delivery of planned features. %\cite{}. %TODO how do i cite this?

Modern software systems are moving towards loosely coupled microservice architectures, resulting in more repositories of smaller scale, tailored towards specialized domains. This trend is driven by the need for flexibility, scalability, and faster development cycles. This approach aligns with modern agile software development practices \cite{francescoResearchArchitectingMicroservices2017}. Along with this trend, developers tend to work on multiple projects simultaneously, which can lead to more interruptions and context switching when problems arise and priorities shift \cite{tregubovImpactTaskSwitching2017, vasilescuSkyNotLimit2016}.

\subsection{Continuous Integration}

Continuous Integration (CI) has become a standard practice in agile software development to accelerate software development and delivery. CI enables frequent code integration into a repository, automating steps like building and testing, thus providing rapid feedback right where the changes are committed. This supports critical aspects of agile software development, enhancing delivery, feedback, and collaboration \cite{ugwuezeContinuousIntegrationDeployment2024}. Figure \ref{fig\:ci-cycle} illustrates a typical CI cycle, where code changes are automatically fetched from source control, built, and tested, with a report generated for the developer.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/ci-cycle.png}
    \caption{Continuous Integration cycle}
    \label{fig:ci-cycle}
\end{figure}

Although Continuous Integration improves feedback loops, it can also add overhead. Effort and infrastructure must be invested to keep pipelines running \cite{hiltonUsageCostsBenefits2016}, and projects may suffer from long build times that harm developer productivity \cite{ghalebEmpiricalStudyLong2019}.

\subsection{Software Project Hosting Platforms} \label{subsection\:Software Project Hosting Platforms}

Modern software projects live on platforms like GitHub or GitLab. GitHub alone hosts 100 million developers and more than 518 million repositories, making it the largest open-source community worldwide \cite{staffOctoverseAILeads2024}.

Development platforms offer tools and services for the entire software development lifecycle, including project hosting, version control, issue tracking, bug reporting, project management, backups, collaborative workflows, and documentation capabilities \cite{GitHubFeatures2025, abrahamssonAgileSoftwareDevelopment2017}.

GitHub Issues are a key feature allowing project-scoped backlogs, tracking tasks, features, and bugs. Issues can be created, assigned, labeled, and commented on by everyone working on a codebase. This feature provides a structured way to manage and prioritize work within a project \cite{Issues}. Figure \ref{fig\:gh-issue} shows an example of a GitHub Issue.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/github/github\_issue.png}
    \caption{Example of a GitHub Issue}
    \label{fig:gh-issue}
\end{figure}

For integrating and reviewing code, GitHub provides Pull Requests. A Pull Request proposes changes to the codebase, integrating a review process to validate changes before merging into the production codebase. Code changes are displayed in a diff format \footnote{TODO explain format}, allowing reviewers to examine the changes made. This process is essential for maintaining code quality and ensuring that changes are validated before merging. Pull requests can be linked to Issues, allowing easy tracking of changes related to specific tasks or bugs \cite{PullRequests}.

Moreover, GitHub also provides a managed solution (GitHub Actions) for running CI pipelines in repositories. CI pipelines are configured by writing workflow files in YAML. Workflows can run self-hosted or hosted by GitHub. A workflow consists of triggers, jobs, and steps. One or more events trigger a workflow, which executes one or more jobs consisting of multiple steps \cite{UnderstandingGitHubActions}. Figure \ref{fig\:gh-workflow} visualizes part of a workflow on GitHub.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/overview-actions-simple.png}
    \caption{Components of a GitHub Action}
    \label{fig:gh-workflow}
\end{figure}

Workflow results and logs can be viewed from multiple places in the GitHub Web User Interface (UI), including the Actions tab, the Pull Request page, and the repository's main page. This integration provides a seamless experience for developers to monitor and manage their CI processes directly within their repositories \cite{GitHubActions2025}.


\section{Generative AI in Software Development}

This section covers the role of Generative AI in modern software development. First, Generative AI and Large Language Models (LLMs) are defined. The second part focuses on the impact of Generative AI on software development practices.

\subsection{Generative AI and Large Language Models}
%TODO add thinking definition of LLMS - and llms are few shot better than zero shot -> cite few shot learners paper
Generative Artificial Intelligence (GenAI) is a subfield of artificial intelligence referring to systems that generate new content based on patterns learned from extensive training data. Advanced machine learning techniques, particularly deep learning, enable these systems to generate text, images, or code that resembles human-generated output \cite{WhatGenerativeAI2021}.

The introduction of the transformer architecture revolutionized the field of text generation and natural language processing (NLP). This architecture laid the groundwork for Large Language Models \cite{changSurveyEvaluationLarge2024, naveedComprehensiveOverviewLarge2024}. Extensive training results in LLMs with billions of parameters, allowing them to understand and generate text in natural languages and diverse programming languages. Research has shown that a model's size impacts its performance, with larger models generally achieving better results in various NLP tasks \cite{kaplanScalingLawsNeural2020}. However, training and operating larger models require significant computational resources \cite{LLMsWhatsLarge, naveedComprehensiveOverviewLarge2024}. Furthermore, despite modern LLMs showing promising results in text generation, they can still hallucinate incorrect or biased content \cite{LLMsWhatsLarge}.

To achieve specific tasks using LLMs, an input prompt is provided to the model. Designing these inputs to guide a model's output is called prompt engineering. This process is crucial for achieving desired results from LLMs, as the quality and specificity of the prompt directly influence the model's output. Text used for input and output of LLMs is tokenized, meaning the text is broken down into smaller units (tokens) for processing. The input is constrained by a model's context window, which is the maximum amount of text the model can process at once \cite{naveedComprehensiveOverviewLarge2024}.

Large Language Models can be accessed via APIs offered by providers like OpenAI, Anthropic, or Google. A selection of LLMs with characteristics is shown in section \ref{subsection\:llm-selection}.

\subsection{Large Language Models in Software Development}

Large Language Models are reshaping software development by automating various tasks \cite{houLargeLanguageModels2024}. With billions of parameters and pre-training on massive codebases, these models exhibit extraordinary capabilities in this area \cite{chenUnveilingPitfallsUnderstanding2025}. Tools like ChatGPT\footnote{link to gpt} and GitHub Copilot\footnote{link to copilot} have become popular in the software development community, providing developers with AI-powered code suggestions and completions \cite{bhargavmallampatiRoleGenerativeAI2025}. These tools are applied in various stages of the software development lifecycle, including requirements engineering, code generation, refactoring, testing, and debugging \cite{houLargeLanguageModels2024, puvvadiCodingAgentsComprehensive2025, bhargavmallampatiRoleGenerativeAI2025}. By using LLMs, development cycle times can be reduced by up to 30 percent \cite{bhargavmallampatiRoleGenerativeAI2025, kalliamvakouResearchQuantifyingGitHub2022}. Furthermore, these tools positively impact developer satisfaction and reduce cognitive load \cite{kalliamvakouResearchQuantifyingGitHub2022}.

Despite the rapid adoption of Generative AI in many areas of software development, this technology still faces limitations. LLMs have difficulty with tasks outside their training scope or requiring specific domain knowledge \cite{houLargeLanguageModels2024}. Limited context windows create challenges when working with large codebases and complex projects, restricting true contextual or business requirement understanding \cite{bhargavmallampatiRoleGenerativeAI2025}. When generating code, LLMs can produce incorrect or insecure outputs, leading to additional bugs and vulnerabilities \cite{houLargeLanguageModels2024, bhargavmallampatiRoleGenerativeAI2025}. Additionally, integrating LLMs can introduce vulnerabilities to prompt injection, where malicious instructions lead to harmful code generation \cite{liuPromptInjectionAttack2024}. Moreover, code generated by LLMs is based on existing training data, raising questions about ownership, responsibility, and intellectual property rights \cite{sauvolaFutureSoftwareDevelopment2024, houLargeLanguageModels2024}.

Facing these challenges, different approaches are actively being developed and researched, including AI Agents \cite{liuMarsCodeAgentAInative2024, yangSWEagentAgentComputerInterfaces2024}, Retrieval Augmented Generation (RAG) approaches \cite{xiaAgentlessDemystifyingLLMbased2024}, and interactive systems \cite{xiaAutomatedProgramRepair2024}. These paradigms aim to enhance LLM capabilities by providing additional context, enabling multi-step reasoning, or allowing interactive feedback loops during code generation and debugging \cite{houLargeLanguageModels2024, puvvadiCodingAgentsComprehensive2025}. Section \ref{subsection\:evolution-apr} discusses these approaches in more detail.

Recent research is exploring solutions integrating LLMs into existing software development practices and workflows, leveraging existing development tools and platforms for seamless integration into the software development lifecycle \cite{puvvadiCodingAgentsComprehensive2025, dohmkeGitHubCopilotMeet2025, IntroducingCodex, sauvolaFutureSoftwareDevelopment2024}.


\section{Automated Program Repair}

Automated Program Repair (APR) describes software that is used to detect and repair bugs in codebases with minimal human intervention. \cite{zhangSurveyLearningbasedAutomated2024} APR is supposed to take over the process of fixing bugs, reducing work load for developers and making time to focus on more relevant work. \cite{houLargeLanguageModels2024}

APR systems fix specific bugs by applying patches, which are often generated using a 3 stage approach: First localizing the bug. Then repairing the bug, in the end validation decides where the bug will be passed on \cite{zhangSurveyLearningbasedAutomated2024, baderGetafixLearningFix2019}. This approach is similar to the bug fixing process of a developer, where the bug is first identified, then fixed and finally tested and reviewed to ensure the fix works as intended \cite{yangSWEagentAgentComputerInterfaces2024}. GetaFix \cite{baderGetafixLearningFix2019} is a prominent example of an APR system being applied at scale. It is used at Meta to automatically fix common bugs in their production codebases.

The field of APR greatly benefited from the rapid advancements in AI and ML. With new research and benchmarks setting new standards in the field.\cite{puvvadiCodingAgentsComprehensive2025,houLargeLanguageModels2024}

In this section we will provide an overview of the evolution of APR, related work, and the current state of APR systems. Followed by a selected list of common APR benchmarks used in research and the industry.

\subsection{Evolution of Automated Program Repair} \label{subsection:evolution-apr}

Automated Program Repair went through multiple paradigm shifts over the years. This evolution of APR can be categorized into key stages, each marked by significant advancements in techniques and methodologies.

\textbf{Traditional Approaches:}

Traditional APR approaches typically rely on manual crafted rules and predefined patterns \cite{liuMarsCodeAgentAInative2024, xiaAutomatedProgramRepair2023,yinThinkRepairSelfDirectedAutomated2024}. These methods can be classified into three main categories: search based, constraint/semantic based, and template based repair techniques.

\begin{itemize}
    \item\textbf{Search based repair} searches for the correct predefined patch in a large search space. \cite{liuMarsCodeAgentAInative2024, huCanGPTO1Kill2024,zhangPATCHEmpoweringLarge2025} A popular example is GenProg, which uses genetic algorithms to evolve patches by mutating existing code and selecting patches based on fitness determined by test cases \cite{legouesGenProgGenericMethod2012}.

    \item\textbf{Constraint/Semantic based repair} synthesizes patches using constraint solvers. The constraints are derived from the program's semantic information and test cases to guide the patch generation process \cite{liuMarsCodeAgentAInative2024, mechtaevAngelixScalableMultiline2016}. Angelix is a prominent example of this approach \cite{mechtaevAngelixScalableMultiline2016}.

    \item\textbf{Template based repair} relies on mined templates for transformations of known bugs. \cite{xiaAutomatedProgramRepair2023} The templates are mined from previous bug fixes developed by humans \cite{xiaAutomatedProgramRepair2023, yinThinkRepairSelfDirectedAutomated2024}. GetaFix is an example of an industrially deployed tool, which learns recurring fix pattern form past fixes \cite{baderGetafixLearningFix2019}
\end{itemize}

These traditional approaches face significant limitations in scalability and adaptability. They struggle to generalize to new and unseen bugs, or to adapt to evolving codebases. Often requiring extensive computational resources and manual effort. \cite{puvvadiCodingAgentsComprehensive2025, xiaAutomatedProgramRepair2024}

\textbf{Learning based Approaches:}

The application of ML introduced new learning based techniques to the field of APR, improving the number and variety of bugs that can be fixed. Deep neural networks use bug fixing patterns from historical fixes as training data, learn how to generate patches to translate buggy code into correct code \cite{xiaAutomatedProgramRepair2023, tangLargeLanguageModels2024}. Prominent examples of  learning based APR systems are CoCoNut \cite{lutellierCoCoNuTCombiningContextaware2020} and Recoder \cite{zhuSyntaxguidedEditDecoder2021}. Despite significant advancements these methods are limited by training data and struggle with unseen bugs. \cite{xiaLessTrainingMore2022}

\textbf{The emerge of LLM based APR:}

The recent explosive growth of LLMs, has transformed the APR space. LLM based APR techniques have demonstrated significant advancements over traditional state of the art techniques, benefitting from the code capabilities of modern LLMs \cite{hossainDeepDiveLarge2024}. For that reason LLMs lay the groundwork of a new APR paradigm \cite{chenUnveilingPitfallsUnderstanding2025, anandComprehensiveSurveyAIDriven2024}.

Different approaches leveraging LLMs have emerged and are being actively researched. These approaches can be categorized into four main paradigms:

\begin{itemize}
    \item \textbf{Retrieval Augmented approaches} enhance bug repair by retrieving relevant context during the repair process. For example code documentation stored in a vector database \cite{puvvadiCodingAgentsComprehensive2025}. This approach allows access to external knowledge during the repair process, enhancing the LLM's ability to understand and fix bugs \cite{houLargeLanguageModels2024, yinThinkRepairSelfDirectedAutomated2024}.

    \item \textbf{Interactive/Conversational approaches} make use of LLMs dialogue capabilities to provide patch validation with instant developer feedback. \cite{xiaAutomatedProgramRepair2024, huCanGPTO1Kill2024} This feedback is used to iterate and refine generated patches with the goal of archive better results \cite{xiaAutomatedProgramRepair2024}

    \item \textbf{Agent based approaches} improve localization and fixing of bugs by equipping LLMs with the ability to access external environments, operate tools (for example: file editors, terminals, web search engines), and make autonomous decisions. \cite{anandComprehensiveSurveyAIDriven2024, puvvadiCodingAgentsComprehensive2025, mengEmpiricalStudyLLMbased2024} Using multi-step reasoning these frameworks reconstruct the cognitive processes of developers using multiple specialized agents. \cite{rondonEvaluatingAgentbasedProgram2025,zhangPATCHEmpoweringLarge2025, leeUnifiedDebuggingApproach2024}. Examples include SWE-Agent \cite{yangSWEagentAgentComputerInterfaces2024}, FixAgent \cite{leeUnifiedDebuggingApproach2024}, MarsCodeAgent \cite{liuMarsCodeAgentAInative2024}, GitHub Copilot.

    \item \textbf{Agentless approaches} are a recent movement towards more lightweight solutions, focusing on simplicity and efficiency. These approaches aim to reduce the complexity of APR systems by cutting complex multi agent coordination and decision making, while maintaining effectiveness in bug fixing \cite{xiaAgentlessDemystifyingLLMbased2024,puvvadiCodingAgentsComprehensive2025}. This approach provides clear guardrails to the LLMs used, improving transparency of the bug fixing approach. Using a three step approach consisting of localization, repair and validation Agentless \cite{xiaAgentlessDemystifyingLLMbased2024} archives promising results at low cost. \cite{xiaAgentlessDemystifyingLLMbased2024, mengEmpiricalStudyLLMbased2024}.
\end{itemize}

Popular LLMs for the mentioned APR techniques include ChatGPT, Codex, CodeLlama, DeepSeek-Coder, and CodeT5 \cite{houLargeLanguageModels2024, yinThinkRepairSelfDirectedAutomated2024,anandComprehensiveSurveyAIDriven2024}.
Despite the significant advancement that come with LLMs, state of the art APR systems still face challenges and limitations. Existing systems suffer from complexity with limited transparency and control over the bug fixing process\cite{xiaAgentlessDemystifyingLLMbased2024,puvvadiCodingAgentsComprehensive2025, houLargeLanguageModels2024}. Additionally, the repair process can be computationally intensive and time-consuming, making it expensive \cite{sobaniaAnalysisAutomaticBug2023, puvvadiCodingAgentsComprehensive2025}. A major hurdle for practical adoption is that many APR systems are designed and evaluated in controlled environments, which makes them difficult to integrate into real-world software development workflows and projects \cite{meemExploringExperiencesAutomated2024,puvvadiCodingAgentsComprehensive2025}.

\subsection{APR benchmarks}

For standardizing evaluation in research of new APR approaches benchmarks have been developed. These benchmarks consist of software bugs and issues, along with their corresponding fixes or tests, which can be used to evaluate the effectiveness of different APR techniques. \cite{anandComprehensiveSurveyAIDriven2024} They are essential for comparing the performance of different APR systems and understanding their strengths and weaknesses. \cite{puvvadiCodingAgentsComprehensive2025} APR benchmarks are available for different programming languages with a selection of popular benchmarks listed in \ref{table:benchmarks} \cite{wangSoftwareDevelopmentLife2025}.

\begin{table}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} p{2.8cm} | p{2.8cm} | p{2.8cm} | p{5cm}  @{}}
        \hline
        \textbf{Model} & \textbf{Languages} & \textbf{Number of Bugs} & \textbf{Description}  \\
        \hline
        QuixBugs \cite{linQuixBugsMultilingualProgram2017} & Python, Java & 40 & small single line bugs  \\ \hline
        Defects4J \cite{justDefects4JDatabaseExisting2014} & Java & 854 & real-world Java bugs  \\ \hline
        ManyBugs \cite{legouesManyBugsIntroClassBenchmarks2015} & C & 185 & real-world C bugs  \\ \hline
        SWE Bench \cite{jimenezSWEbenchCanLanguage2024} & Python & 2294 & Real GitHub repository defects \\\hline
        SWE Bench Lite & Python & 300 & selected real GitHub defects \\
        \hline
    \end{tabular*}
    \caption{Overview of APR benchmarks}
    \label{table:benchmarks}
\end{table}