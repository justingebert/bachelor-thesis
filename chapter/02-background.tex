In this chapter, the required theoretical background and context for this thesis are explained. First, fundamental concepts of software development, the Agile \ac{SDLC}, \acf{CI}, and software project hosting platforms are introduced. The second part explores \ac{GenAI} and \acp{LLM} with their rising role in software development practices. The third part examines the evolution and current state of \ac{APR} with examples of existing approaches.

\section{Software Development}

This section introduces core concepts of software development, starting with the \ac{SDLC}, followed by the importance of \ac{CI} in modern software development, and the role of software project hosting platforms.

\subsection{Software Development Lifecycle}

Engineering and developing software is a complex process, consisting of multiple different tasks. To structure this process, \ac{SDLC} models have been introduced. These frameworks constantly evolve to adapt to the changing needs of software development. One of the most promising and widely used \ac{SDLC} models today is Agile \cite{rupareliaSoftwareDevelopmentLifecycle2010, abrahamssonAgileSoftwareDevelopment2017}.

The Agile lifecycle introduces an iterative approach to software development, focusing on collaboration, feedback, and adaptability. The goal of Agile is frequent delivery of small functional software features, allowing continuous improvement and adaptation to changing requirements \cite{rupareliaSoftwareDevelopmentLifecycle2010, abrahamssonAgileSoftwareDevelopment2017}. Frameworks like Scrum or Kanban are used to apply Agile in a development environment \cite{zayatFrameworkStudyAgile2020}.

An Agile iteration consists of multiple stages, each contributing to the overall development cycle. Figure \ref{fig:agile-cycle} visualizes an example of an Agile iteration interpretation. Iterations start with a planning phase where requirements are gathered and prioritized. Secondly, the architecture and design of the required changes are constructed in the design phase. The third stage involves developing the prioritized requirements. After development, the changes are tested for issues or bugs in the testing stage. Upon successful integration and testing, the changes are released in the deployment stage. Finally, internal and user feedback is collected for review \cite{huoSoftwareQualityAgile2004}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/agile-cycle.png}
    \caption{Agile software development lifecycle, Source: \cite{7MistakesIve2020}}
    \label{fig:agile-cycle}
\end{figure}

When bugs arise during an iteration, requirements can be reprioritized, and the iteration can be adapted to fix these issues. This adaptability is a key feature of Agile software development, allowing teams to quickly respond to changing requirements and issues. However, this can slow down the delivery of planned features. %\cite{}. %TODO cite this

Modern software systems are moving towards loosely coupled microservice architectures, resulting in more repositories of smaller scale, tailored towards specialized domains. This trend is driven by the need for flexibility, scalability, and faster development cycles. This approach aligns with modern Agile software development practices \cite{francescoResearchArchitectingMicroservices2017}. Along with this trend, developers tend to work on multiple projects simultaneously, which can lead to more interruptions and context switching when problems arise and priorities shift \cite{tregubovImpactTaskSwitching2017, vasilescuSkyNotLimit2016}.

\subsection{Continuous Integration}

\Acf{CI} has become a standard practice in Agile software development to accelerate development and delivery. CI enables frequent code integration into a repository, by automating steps like building and testing, thus providing rapid feedback right where the changes are committed. This supports critical aspects of Agile software development, enhancing delivery, feedback, and collaboration \cite{ugwuezeContinuousIntegrationDeployment2024}. Figure \ref{fig:ci-cycle} illustrates a typical CI cycle, where code changes are automatically fetched from source control, built, and tested and the results are reported back to developers.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/ci-cycle.png}
    \caption{Continuous Integration cycle, Source:~\cite{lovettTop12Benefits2023}}
    \label{fig:ci-cycle}
\end{figure}

Although \ac{CI} improves feedback loops, it can also result in additional overhead. Effort and infrastructure must be invested to keep pipelines running \cite{hiltonUsageCostsBenefits2016}, and projects may suffer from long build times that harm developer productivity \cite{ghalebEmpiricalStudyLong2019}.

\subsection{Software Project Hosting Platforms} \label{subsection:Software Project Hosting Platforms}

Modern software projects are typically hosted on platforms such as GitHub or GitLab. GitHub is the largest, with over 100 million developers and more than 518 million repositories, making it the world's leading open-source community \cite{staffOctoverseAILeads2024}.

These development platforms offer tools and services for the entire \ac{SDLC}, including project hosting, version control, issue tracking, bug reporting, project management, backups, collaborative workflows, and documentation capabilities \cite{GitHubFeatures2025, abrahamssonAgileSoftwareDevelopment2017}.

A key feature of GitHub is GitHub issues, this feature enables backlogs and tracking of tasks, features and bugs for individual repositories. Issues can be created, assigned, labeled, and commented on by everyone working on a codebase. This feature provides a structured way to manage and prioritize work within a project \cite{Issues}. Figure \ref{fig:gh-issue} shows an example of a GitHub issue.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/github/github_issue.png}
    \caption{Example of a GitHub issue, Source: screenshot}
    \label{fig:gh-issue}
\end{figure}

For integrating and reviewing code, GitHub provides pull requests. A pull request proposes changes to the codebase, integrating a review process to validate changes before merging into the production codebase. Code changes are displayed in a diff format\footnote{A diff format shows the difference between two files by highlighting added, removed, or modified lines \cite{WhatDiffUnderstanding}.}, allowing reviewers to examine the changes made. This process is essential for maintaining code quality and ensuring that changes are validated before merging. Pull requests can be linked to Issues, allowing easy tracking of changes related to specific tasks or bugs \cite{PullRequests}.

Additionally, GitHub offers a managed solution for running CI pipelines called GitHub Actions. These pipelines are configured using workflow files written in YAML\footnote{YAML is a human-readable data serialization language \cite{OfficialYAMLWeb}.}. Workflows can run on either self-hosted or GitHub-hosted runners. Each workflow is defined by triggers, jobs, and steps. Specific events trigger the workflow, which then executes one or more jobs, each composed of multiple steps \cite{UnderstandingGitHubActionsa}. Figure \ref{fig:gh-workflow} illustrates the components of a GitHub workflow.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/overview-actions-simple.png}
    \caption{Components of a GitHub Action, Source:~\cite{UnderstandingGitHubActionsa}}
    \label{fig:gh-workflow}
\end{figure}

The results and logs of a workflow can be viewed from multiple places in the GitHub User Interface, including the Actions tab, Pull Request page, and the repository's main page. This integration provides a seamless experience for developers to monitor and manage their CI processes directly within a repository \cite{GitHubActions2025}.


\section{Generative AI in Software Development}

This section examines the role of \ac{GenAI} in modern software development. First, \ac{GenAI} and \acp{LLM} are defined. The second part focuses on the impact of \ac{GenAI} on software development practices.

\subsection{Generative AI and Large Language Models}
\ac{GenAI} is a subfield of \ac{AI} referring to systems that generate new content based on patterns learned from extensive training data. Recent advances in machine learning, especially deep learning, have made it possible for generative systems to produce text, images, or code that resembles human-created content \cite{WhatGenerativeAI2021}.

The transformer architecture marked a major breakthrough in text generation and \ac{NLP} research.
This architecture lays the groundwork for Large Language Models \cite{changSurveyEvaluationLarge2024, naveedComprehensiveOverviewLarge2024}. Extensive training, results in \acp{LLM} with billions of parameters, allowing them to understand and generate text in diverse natural and programming languages. Research has shown that a model's size directly impacts its performance, with larger models generally achieving better results in various \ac{NLP} tasks \cite{kaplanScalingLawsNeural2020}. However, training and operating larger models requires significant computational resources \cite{LLMsWhatsLarge, naveedComprehensiveOverviewLarge2024}. Furthermore, despite modern \acp{LLM} showing promising results in text generation, they can still hallucinate incorrect or biased content \cite{LLMsWhatsLarge}.

When using a \ac{LLM}, an input prompt must be provided. Designing this input is a process known as prompt engineering. The quality and specificity of the prompt directly influence the model's output. In zero-shot prompting, the model is given only the task description, while in few-shot prompting, a few relevant examples are included to better guide the model's behavior. Brown et al.~\cite{brownLanguageModelsAre2020} showed that few-shot prompting can remarkably improve model performance across diverse tasks.

Text used for input and output is tokenized, meaning the text is broken down into smaller units (tokens) for processing. The input is constrained by a model's context window, which is the maximum amount of text the model can process at once \cite{naveedComprehensiveOverviewLarge2024}.

\acp{LLM} can be accessed via APIs offered by providers like OpenAI, Anthropic, or Google. A selection of \acp{LLM} with their characteristics is listed in Section \ref{subsection:llm-selection}.

\subsection{Large Language Models in Software Development}

\acp{LLM} are reshaping software development by automating various tasks \cite{houLargeLanguageModels2024}. With billions of parameters and pre-training on massive codebases, these models show extraordinary capabilities in this area \cite{chenUnveilingPitfallsUnderstanding2025}. Tools like ChatGPT \cite{IntroducingChatGPT2024} and GitHub Copilot \cite{dohmkeGitHubCopilotMeet2025} have become popular in the software development community, providing developers with AI-powered code suggestions and completions \cite{bhargavmallampatiRoleGenerativeAI2025}. These tools are applied in various stages of the \ac{SDLC}, including requirements engineering, code generation, refactoring, testing, and debugging \cite{houLargeLanguageModels2024, puvvadiCodingAgentsComprehensive2025, bhargavmallampatiRoleGenerativeAI2025}. By using \acp{LLM} for these tasks, development cycle times can be reduced by up to 30 percent \cite{bhargavmallampatiRoleGenerativeAI2025, kalliamvakouResearchQuantifyingGitHub2022}. Furthermore, research has shown that these tools positively impact developer satisfaction and reduce cognitive load \cite{kalliamvakouResearchQuantifyingGitHub2022}.

Despite the rapid adoption of \ac{GenAI} in many areas of software development, this technology still faces limitations. \acp{LLM} face difficulties with tasks that are outside of their training scope or require specific domain knowledge \cite{houLargeLanguageModels2024}. Limited context windows create challenges when working with large codebases and complex projects, restricting true contextual or business requirement understanding \cite{bhargavmallampatiRoleGenerativeAI2025}. When generating code, \acp{LLM} can produce incorrect or insecure outputs, leading to unexpected bugs or vulnerabilities \cite{houLargeLanguageModels2024, bhargavmallampatiRoleGenerativeAI2025}. Additionally, integrating \acp{LLM} can introduce vulnerabilities threats like prompt injection, where malicious instructions are injected and can lead to generation of harmful code \cite{liuPromptInjectionAttack2024}. Moreover, code generated by \acp{LLM} is based on existing training data, raising questions about ownership, responsibility, and intellectual property rights \cite{sauvolaFutureSoftwareDevelopment2024, houLargeLanguageModels2024}.

Facing these challenges, different approaches are actively being developed and researched, including \ac{AI} Agents \cite{liuMarsCodeAgentAInative2024, yangSWEagentAgentComputerInterfaces2024}, \ac{RAG} approaches \cite{xiaAgentlessDemystifyingLLMbased2024}, and interactive systems \cite{xiaAutomatedProgramRepair2024}. These paradigms aim to enhance LLM capabilities by providing additional context, enabling multi-step reasoning, or allowing interactive feedback loops during code generation and debugging \cite{houLargeLanguageModels2024, puvvadiCodingAgentsComprehensive2025}. Section \ref{subsection:evolution-apr} discusses the mentioned approaches in more detail in the context of \ac{APR}.

Recent research is exploring solutions which integrate \acp{LLM} into existing software development practices and workflows, leveraging existing development tools and platforms for seamless integration into the \ac{SDLC} \cite{puvvadiCodingAgentsComprehensive2025, dohmkeGitHubCopilotMeet2025, IntroducingCodex, sauvolaFutureSoftwareDevelopment2024}.

\section{Automated Program Repair}

\ac{APR} describes software used to detect and repair bugs in codebases with minimal human intervention \cite{zhangSurveyLearningbasedAutomated2024}. The goal of APR is to automate the bug-fixing process, reducing workload for developers and allowing them to focus on more relevant tasks \cite{houLargeLanguageModels2024}.

APR systems fix specific bugs by applying patches, typically generated using a three-stage approach: localizing the bug, repairing it, and finally validating the fix \cite{zhangSurveyLearningbasedAutomated2024, baderGetafixLearningFix2019}. This approach mirrors a developer's bug-fixing process, where the bug is identified, fixed, and then tested and reviewed to ensure the fix works as intended \cite{yangSWEagentAgentComputerInterfaces2024}. GetaFix is a prominent example of an APR system applied at scale. It is used at Meta to automatically fix common bugs in their production codebases. \cite{baderGetafixLearningFix2019}

The field of APR has greatly benefited from rapid advancements in \ac{AI}, with new research and benchmarks continually setting higher standards \cite{puvvadiCodingAgentsComprehensive2025, houLargeLanguageModels2024}.

This section provides an overview of the evolution of APR, related work, and the current state of APR systems, followed by a selected list of APR benchmarks used in research and industry.

\subsection{Evolution of Automated Program Repair Techniques} \label{subsection:evolution-apr}

\ac{APR} has experienced multiple paradigm shifts over the years, categorized into key stages marked by significant advancements in techniques and methodologies.

\textbf{Traditional Approaches:}

Traditional APR approaches typically rely on manually crafted rules and predefined patterns \cite{liuMarsCodeAgentAInative2024, xiaAutomatedProgramRepair2023, yinThinkRepairSelfDirectedAutomated2024}. These methods can be classified into three main categories: search-based, constraint/semantic-based, and template-based repair techniques.

\begin{itemize}
    \item \textbf{Search-based repair} searches for the correct predefined patch within a large search space \cite{liuMarsCodeAgentAInative2024, huCanGPTO1Kill2024, zhangPATCHEmpoweringLarge2025}. A popular example is GenProg, which uses genetic algorithms to evolve patches by mutating existing code and selecting patches based on fitness determined by test cases \cite{legouesGenProgGenericMethod2012}.

    \item \textbf{Constraint/Semantic-based repair} synthesizes patches using constraint solvers derived from the program's semantic information and test cases \cite{liuMarsCodeAgentAInative2024, mechtaevAngelixScalableMultiline2016}. Angelix is a prominent example of this approach \cite{mechtaevAngelixScalableMultiline2016}.

    \item \textbf{Template-based repair} relies on mined templates for transformations of known bugs \cite{xiaAutomatedProgramRepair2023}. These templates are mined from previous human-developed bug fixes \cite{xiaAutomatedProgramRepair2023, yinThinkRepairSelfDirectedAutomated2024}. GetaFix is an industrially deployed tool, learning recurring fix patterns from past fixes \cite{baderGetafixLearningFix2019}.
\end{itemize}

These traditional approaches face significant limitations in scalability and adaptability. They struggle to generalize to new and unseen bugs or adapt to evolving codebases, often requiring extensive computational resources and manual effort \cite{puvvadiCodingAgentsComprehensive2025, xiaAutomatedProgramRepair2024}.

\textbf{Learning-based Approaches:}

Machine learning techniques introduced learning-based APR approaches, increasing the variety and number of bugs that can be fixed. Deep neural networks leverage bug-fixing patterns from historical fixes as training data to learn how to generate patches and translate buggy code into correct code \cite{xiaAutomatedProgramRepair2023, tangLargeLanguageModels2024}. Prominent examples include CoCoNut \cite{lutellierCoCoNuTCombiningContextaware2020} and Recoder \cite{zhuSyntaxguidedEditDecoder2021}. Despite significant advancements, these methods remain limited by training data and struggle with unseen bugs \cite{xiaLessTrainingMore2022}.

\textbf{The Emergence of LLM-based APR:}

The recent growth of \acp{LLM} has transformed the APR field. LLM-based APR techniques demonstrate significant advancements over traditional state-of-the-art techniques, leveraging the advanced code-generation capabilities of modern \acp{LLM} \cite{hossainDeepDiveLarge2024}. Consequently, \acp{LLM} form the foundation of a new APR paradigm \cite{chenUnveilingPitfallsUnderstanding2025, anandComprehensiveSurveyAIDriven2024}.

Recent research has led to the emergence of several LLM-based APR paradigms, which can be grouped into four main categories:

\begin{itemize}
    \item \textbf{\ac{RAG} approaches} enhance bug repair by retrieving relevant context, such as code documentation stored in vector databases, during the repair process \cite{puvvadiCodingAgentsComprehensive2025}. This approach allows access to external knowledge, enhancing \acp{LLM}' bug-fixing capabilities \cite{houLargeLanguageModels2024, yinThinkRepairSelfDirectedAutomated2024}.

    \item \textbf{Interactive/Conversational approaches} utilize \acp{LLM}' dialogue capabilities, providing instant developer feedback during patch validation \cite{xiaAutomatedProgramRepair2024, huCanGPTO1Kill2024}. This iterative feedback loop refines generated patches to achieve better outcomes \cite{xiaAutomatedProgramRepair2024}.

    \item \textbf{Agent-based approaches} enhance bug localization and repair by equipping \acp{LLM} with the ability to access external environments, operate tools (e.g. file editors, terminals, web search engines), and make autonomous decisions \cite{anandComprehensiveSurveyAIDriven2024, puvvadiCodingAgentsComprehensive2025, mengEmpiricalStudyLLMbased2024}. Using multi-step reasoning, these frameworks replicate developers' cognitive processes through specialized agents \cite{rondonEvaluatingAgentbasedProgram2025, zhangPATCHEmpoweringLarge2025, leeUnifiedDebuggingApproach2024}. Examples include SWE-Agent \cite{yangSWEagentAgentComputerInterfaces2024}, FixAgent \cite{leeUnifiedDebuggingApproach2024}, MarsCodeAgent \cite{liuMarsCodeAgentAInative2024}, and GitHub Copilot \cite{dohmkeGitHubCopilotMeet2025}.

    \item \textbf{Agentless approaches} focus on simplicity and efficiency, reducing complex multi-agent coordination while maintaining effectiveness \cite{xiaAgentlessDemystifyingLLMbased2024, puvvadiCodingAgentsComprehensive2025}. These approaches provide clear guardrails for \acp{LLM}, improving transparency. The three-step approach (localization, repair, validation) of Agentless approaches achieves promising results at low cost \cite{xiaAgentlessDemystifyingLLMbased2024, mengEmpiricalStudyLLMbased2024}.
\end{itemize}

Popular \acp{LLM} for APR include ChatGPT, Codex, CodeLlama, DeepSeek-Coder, and CodeT5 \cite{houLargeLanguageModels2024, yinThinkRepairSelfDirectedAutomated2024, anandComprehensiveSurveyAIDriven2024}. Despite the significant advancements brought by \acp{LLM}, state-of-the-art APR systems continue to face notable challenges and limitations. Existing systems are often complex, with limited transparency and control over the bug-fixing process \cite{xiaAgentlessDemystifyingLLMbased2024, puvvadiCodingAgentsComprehensive2025, houLargeLanguageModels2024}. Additionally, the repairs are computationally intensive and time-consuming, leading to high costs \cite{sobaniaAnalysisAutomaticBug2023, puvvadiCodingAgentsComprehensive2025}.
Furthermore a barrier to practical adoption remains: most APR systems are developed and evaluated in controlled environments. Consequently, there is still a lack of research and experience on integrating these approaches into real-world software development workflows and projects \cite{meemExploringExperiencesAutomated2024, puvvadiCodingAgentsComprehensive2025}.


\subsection{APR Benchmarks}

To standardize the evaluation of new APR approaches, benchmarks have been developed. These benchmarks consist of software bugs and issues, along with their corresponding fixes or tests, which can be used to evaluate the effectiveness of different APR techniques \cite{anandComprehensiveSurveyAIDriven2024}. They are essential for comparing the performance of different APR systems and for understanding their strengths and weaknesses \cite{puvvadiCodingAgentsComprehensive2025}. APR benchmarks are available for various programming languages, with a selection of popular benchmarks listed in Table\ref{table:benchmarks} below \cite{wangSoftwareDevelopmentLife2025}.

%TODO descriptions need citations
\begin{table}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} p{2.8cm} | p{2.8cm} | p{2.8cm} | p{5cm}  @{}}
        \hline
        \textbf{Model} & \textbf{Languages} & \textbf{Number of Bugs} & \textbf{Description}  \\
        \hline
        QuixBugs \cite{linQuixBugsMultilingualProgram2017} & Python, Java & 40 & small single line bugs  \\ \hline
        Defects4J \cite{justDefects4JDatabaseExisting2014} & Java & 854 & real-world Java bugs  \\ \hline
        ManyBugs \cite{legouesManyBugsIntroClassBenchmarks2015} & C & 185 & real-world C bugs  \\ \hline
        SWE Bench \cite{jimenezSWEbenchCanLanguage2024} & Python & 2294 & Real GitHub repository defects \\\hline
        SWE Bench Lite \cite{SWEbenchLite} & Python & 300 & selected real GitHub defects \\
        \hline
    \end{tabular*}
    \caption{Overview of APR benchmarks}
    \label{table:benchmarks}
\end{table}